{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_GcweduxBU9"
      },
      "source": [
        "# **Architectural Likeness Elucidator (ALE) - Primer Modelo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozslSr3O77Mh"
      },
      "source": [
        "Primero se descargan los datasets de Kaggle medinte el uso de su API y un token de usario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "isv2BDwnxzFo",
        "outputId": "8007c1c4-b5fc-4831-e3d9-c15250fe0d92"
      },
      "outputs": [],
      "source": [
        "#!pip install -q kaggle\n",
        "#from google.colab import files\n",
        "#files.upload()\n",
        "#!mkdir ~/.kaggle\n",
        "#!cp kaggle.json ~/.kaggle/\n",
        "#!chmod 600 ~/.kaggle/kaggle.json\n",
        "#!kaggle datasets download -d dumitrux/architectural-styles-dataset\n",
        "#!unzip architectural-styles-dataset.zip -d /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT6VyhEz8G8v"
      },
      "source": [
        "Importar las librerias necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "a9qBpE8I1B1n",
        "outputId": "274c640f-a9d6-4e91-cdc2-d5f51524893b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import cv2\n",
        "import glob\n",
        "from PIL import Image\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX_rkKqk8mTY"
      },
      "source": [
        "Obtener la dirección de las imágenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnC6QTiw5eWR"
      },
      "outputs": [],
      "source": [
        "dataDIR = \"../data/architectural-styles-dataset/\"\n",
        "datasetDIR = pathlib.Path(dataDIR)\n",
        "\n",
        "imageCount = len(list(datasetDIR.glob(\"*/*.jpg\")))\n",
        "print(\"Total Images in Dataset:\")\n",
        "print(imageCount)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC_tY_fE8-iv"
      },
      "source": [
        "Definir Estilos Arquitectónicos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UE5T2kF3898x"
      },
      "outputs": [],
      "source": [
        "styles = ['Achaemenid architecture','American craftsman style','American Foursquare architecture','Ancient Egyptian architecture','Art Deco architecture',\n",
        "    'Art Nouveau architecture','Baroque architecture','Bauhaus architecture','Beaux-Arts architecture','Byzantine architecture',\n",
        "    'Chicago school architecture','Colonial architecture','Deconstructivism','Edwardian architecture','Georgian architecture',\n",
        "    'Gothic architecture','Greek Revival architecture','International style','Novelty architecture','Palladian architecture',\n",
        "    'Postmodern architecture','Queen Anne architecture','Romanesque architecture','Russian Revival architecture','Tudor Revival architecture']\n",
        "\n",
        "numStyles = len(styles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06fznIsqyAYm"
      },
      "source": [
        "Resize images in order to normalize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtTI0Ycm6KMV"
      },
      "outputs": [],
      "source": [
        "# Separate image dataset into features and labels (target = style)\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# Set size for images to be resized to\n",
        "size = (256, 256)\n",
        "\n",
        "# Put images in X and their labels in y\n",
        "for style in styles[:]:\n",
        "    imgFile = glob.glob(f'content/architectural-styles-dataset/**/{style}/*.jpg', recursive = True)\n",
        "\n",
        "    # Resize and grayscale each image\n",
        "    for i, f in enumerate(imgFile):\n",
        "        img = cv2.imread(f)\n",
        "        img = cv2.resize(img, size, interpolation = cv2.INTER_AREA)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img = np.array(img)\n",
        "        img = img.astype('float32')\n",
        "        img /= 255\n",
        "        X.append(img)\n",
        "        y.append(style)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oqATN2wyIK8"
      },
      "source": [
        "Create train and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PR7pi-ccAYnG"
      },
      "outputs": [],
      "source": [
        "trainDs = tf.keras.utils.image_dataset_from_directory(datasetDIR, validation_split=0.2,subset=\"training\",seed=123, image_size=(256,256), batch_size=32)\n",
        "valDs = tf.keras.utils.image_dataset_from_directory(datasetDIR, validation_split=0.2,subset=\"validation\",seed=123,image_size=(256,256),batch_size=32 )\n",
        "\n",
        "className = trainDs.class_names\n",
        "print(className)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ENBv8xHyOzR"
      },
      "source": [
        "Plot some images from the dataset with their respective styles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Oup8-8pBcSK"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for images, styles in trainDs.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3,3,i+1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(className[styles[i]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx9svhLSyalM"
      },
      "source": [
        "Normalize dataset layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZarNHyqbB0Ep"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "trainDs = trainDs.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "valDs = valDs.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "normalizationLayer = layers.Rescaling(1./255)\n",
        "\n",
        "normalizedDs = trainDs.map(lambda x, y: (normalizationLayer(x),y))\n",
        "imageBatch, labelsBatch = next(iter(normalizedDs))\n",
        "firstImage = imageBatch[0]\n",
        "\n",
        "# Notice how the pixel value are now in [0,1]\n",
        "print(np.min(firstImage), np.max(firstImage))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dENb6mxyfCN"
      },
      "source": [
        "Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrRnfTJ3rBxH"
      },
      "outputs": [],
      "source": [
        "numClasses = len(className)\n",
        "\n",
        "model  = Sequential([layers.Rescaling(1./255, input_shape=(256, 256, 3)), layers.Conv2D(16,3,padding=\"same\",activation=\"relu\"), layers.MaxPooling2D(), layers.Conv2D(32,3,padding=\"same\",activation=\"relu\"), layers.MaxPooling2D(),layers.Conv2D(64,3,padding=\"same\",activation=\"relu\"),layers.MaxPooling2D(),layers.Dropout(0.2),layers.Flatten(),layers.Dense(128,activation=\"relu\"),layers.Dense(numClasses)])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AbOgEWXy0sK"
      },
      "source": [
        "Sumarize the previously created model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9wHkVoCra2i"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz-0gj55y46t"
      },
      "source": [
        "Train the model with the proper datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6QON04Rrio9"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "history = model.fit(trainDs,validation_data=valDs,epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtI3xR21y7pT"
      },
      "source": [
        "Test the trained model with new pictures in order to find errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L07ht_9Br8uk"
      },
      "outputs": [],
      "source": [
        "#ArtDeco\n",
        "img = tf.keras.utils.load_img(\"../data/TestImages/ArtDecoEx.png\", target_size=(256, 256))\n",
        "\n",
        "imgArray  = tf.keras.utils.img_to_array(img)\n",
        "imgArray = tf.expand_dims(imgArray, 0) #Create batch\n",
        "\n",
        "predictions = model.predict(imgArray)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\"This image most likely belongs to {} with a {:.2f} percent confidence.\".format(className[np.argmax(score)], 100 *  np.max(score)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEUKieVmFNWs"
      },
      "outputs": [],
      "source": [
        "#Post-Modern\n",
        "img2 = tf.keras.utils.load_img(\"/content/imagen_2024-04-24_213807021.png\", target_size=(256, 256))\n",
        "\n",
        "imgArray2  = tf.keras.utils.img_to_array(img2)\n",
        "imgArray2 = tf.expand_dims(imgArray2, 0) #Create batch\n",
        "\n",
        "predictions2 = model.predict(imgArray2)\n",
        "score2 = tf.nn.softmax(predictions2[0])\n",
        "\n",
        "print(\"This image most likely belongs to {} with a {:.2f} percent confidence.\".format(className[np.argmax(score2)], 100 *  np.max(score2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIhMtFP2VGVP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
